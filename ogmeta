#!/usr/bin/env python3

import argparse
import json
from oglaf import knowledge, ogweb


parser = argparse.ArgumentParser(description='Oglaf comic manager')

# Fetch, add, delete, search, list-all options
parser.add_argument('-fetchnew', action='store_true',
    help='Fetch new strips from the Oglaf archive')
parser.add_argument('-a', action='store_true',
    help='Add - Add tags to strips')
parser.add_argument('-d', action='store_true',
    help='Delete - Delete tags from strips')
parser.add_argument('-s', action='store_true',
    help='Search - Find tags in strips [DEFAULT]')
parser.add_argument('-l', action='store', default=None, metavar='tags|arcs|urls|titles',
    help='List - List all [DEFAULT: tags]')

parser.add_argument('-tag', action='append', metavar='word', default=None,
    help='Tag - Keyword relevant to your activity, can be specified more than once')
parser.add_argument('-arc', action='append', metavar='label', default=None,
    help='Arc - Story arc')
parser.add_argument('-title', action='append',
    help='Title - The title of a comic related to your activity, can be specified more than once')
parser.add_argument('-url', action='append',
    help='The URL of a comic related to your activity, can be specified more than once')
args = parser.parse_args()


tome = knowledge.TomeOfKnowledge()


def fetch_new():
    ''' Update the tome with new strips from the Oglaf web archive '''
    archive = ogweb.OGWeb()
    archive.get_newest()
    
    if archive.newest_url is None:
        print("Couldn't read the archive, maybe try later???")
        return False
    elif archive.newest_url in tome.urls:
        print("No new strips to add.")
        return False

    newest_known_number = max(sorted(tome.order.keys()))
    orig_newest_known_number = newest_known_number
    newest_known_title = tome.order[newest_known_number]
    newest_known_url = tome.titles[newest_known_title]['urls'][0]

    # There's at least one strip that can be found by navigating "next" /
    # "previous" that's not in the archive. (I'm looking at you
    # https://www.oglaf.com/trueslut2012/)
    #
    # Given a known strip URL, fetch it and start crawling the "next"
    # and any other surprise strips until we get through the newest
    # published strip.
    #
    known_page = archive.get_page(newest_known_url)

    # Sigh, sometimes a strip gets added and then removed.  If the newest
    # known strip isn't found, try for the one before that.
    if known_page is None:
        newest_known_number = max(sorted(tome.order.keys())) - 1
        newest_known_title = tome.order[newest_known_number]
        newest_known_url = tome.titles[newest_known_title]['urls'][0]
        known_page = archive.get_page(newest_known_url)
    if known_page is None:
        print("Can't find my place in the archive, so quitting!")
        exit()

    archive.get_strip_urls(known_page)
    strip_url = archive.strip['next']
    added = 0
    while strip_url:
        strip_page = archive.get_page(strip_url)

        # Enumerate all page links for this one, including epilogues
        archive.get_strip_urls(strip_page)
        strip_title = archive.strip['title']

        print("Adding '{}'".format(strip_title))
        tome.add_strip(
            title = strip_title,
            urls = archive.strip['urls'],
            publishorder = orig_newest_known_number + added + 1
        )
        added += 1
        strip_url = archive.strip['next']

    if added > 0:
        return True
    else:
        return False


def urls2titles():
    ''' Given a TomeOfKnowledge return a title for a given list of URLs '''
    if not args.title:
        args.title = list()
    for url in args.url:
        found = False
        for tome_url in tome.urls.keys():
            if url in tome_url:
                found = True
                args.title.append(tome.urls[tome_url])
                break
        if not found:
            print("No strip found related to URL: {}".format(url))
    if len(args.title) == 0:
        print("Couldn't find any titles for your URLs, so quitting.  Bye.")
        quit()


#################################################


# FETCH NEW metadata from the website
if args.fetchnew:
    if fetch_new():
        tome.save_meta()
        print("Saved metadata")
    quit()


# ADD OR DELETE TAGS/ARCS
elif args.a or args.d:
    changed = 0
    if not args.title and not args.url:
        print("You need to specify at least 1 title or URL to modify.")
        quit()

    # Title is the correlation attribute, so convert any user-provided
    # URLs into args.title so we can just work on titles from here.
    if args.url:
        urls2titles()

    # Iterate over each title specified
    for title in args.title:
        # Match the documented title's case, updating args.title accordingly
        known_title = False
        ltitle = title.lower()
        if ltitle in tome.lctitles.keys():
            title = tome.lctitles[ltitle]
            known_title = True
        if not known_title:
            print("Can't find title '{}'".format(title))
            continue

        # Process each tag for each title
        if args.tag is not None:
            for tag in args.tag:
                change = True
                ltag = tag.lower()
                if ltag in tome.lctags.keys():
                    # Prefer the case of existing tags so we don't end up with separate
                    # tags like: Tits, TITS, tIts
                    tag = tome.lctags[ltag]
                    if args.a and title in tome.tags[tag]:
                        print("Tag '{}' already applied to '{}'".format(tag, title))
                        change = False
                else:
                    if args.d:
                        print("Tag '{}' is not applied to '{}'".format(tag, title))
                        change = False

                # Actually make the addition that was requested and validated
                if change and args.a:
                    if tag not in tome.tags.keys():
                        tome.tags[tag] = list()
                    tome.tags[tag].append(title)
                    tome.titles[title]['tags'].append(tag)
                    changed += 1

                # Actually make the deletion that was requested and validated
                elif change and args.d:
                    tome.tags[tag].remove(title)
                    tome.titles[title]['tags'].remove(tag)
                    changed += 1

        # Process each arc for each title
        if args.arc is not None:
            for arc in args.arc:
                change = True
                larc = arc.lower()
                if larc in tome.lcarcs.keys():
                    # Prefer the case of existing arcs so we don't end up with separate
                    # arcs like: Cumsprite, cumSPRite, etc.
                    arc = tome.lcarcs[larc]
                    if args.a and title in tome.arcs[arc]:
                        print("Arc '{}' already applied to '{}'".format(arc, title))
                        change = False
                else:
                    if args.d:
                        print("Arc '{}' is not applied to '{}'".format(arc, title))
                        change = False

                # Actually make the addition that was requested and validated
                if change and args.a:
                    if arc not in tome.arcs.keys():
                        tome.arcs[arc] = list()
                    tome.arcs[arc].append(title)
                    tome.titles[title]['arcs'].append(arc)
                    changed += 1

                # Actually make the deletion that was requested and validated
                elif change and args.d:
                    tome.arcs[arc].remove(title)
                    tome.titles[title]['arcs'].remove(arc)
                    changed += 1

    # Save data back to files
    if changed > 0:
        tome.save_meta()
        print("{} changes complete".format(changed))
    quit()


# LIST-ALL
# tags/arcs/urls/titles
elif args.l:
    if args.l == 'tags':
        print('\n'.join(sorted(tome.tags.keys())))
    elif args.l == 'arcs':
        print('\n'.join(sorted(tome.arcs.keys())))
    elif args.l == 'urls':
        print('\n'.join(sorted(tome.urls.keys())))
    elif args.l == 'titles':
        print('\n'.join(sorted(tome.titles.keys())))
    else:
        parser.print_help()


# LIST
# Tags/arcs by title or URL
elif args.title or args.url:
    # Get title(s) from supplied URL(s)
    if args.url:
        urls2titles()

    for thistitle in args.title:
        lthistitle = thistitle.lower()
        if lthistitle in tome.lctitles.keys():
            proper_title = tome.lctitles[lthistitle]
            print("{} (publish order: {})".format(proper_title, tome.titles[proper_title]['publishOrder']))
            for arc in sorted(tome.titles[proper_title]['arcs']):
                print('\t' + arc + ' (arc)')
            for tag in sorted(tome.titles[proper_title]['tags']):
                print('\t' + tag + ' (tag)')
            for url in sorted(tome.titles[proper_title]['urls']):
                print('\tURL: ' + url)
        else:
            print("Title '{}' not found.".format(thistitle))


# SEARCH
# Will use logical OR if multiple tags/arcs provided
elif args.tag or args.arc:
    hits = dict()

    if args.tag:
        for tag in args.tag:
            ltag = tag.lower()
            for lctag in tome.lctags:
                if ltag in lctag:
                    proper_tag = tome.lctags[lctag]
                    for title in tome.tags[proper_tag]:
                        if title not in hits.keys():
                            hits[title] = list()
                        hits[title].append(proper_tag)

    if args.arc:
        for arc in args.arc:
            larc = arc.lower()
            for lcarc in tome.lcarcs:
                if larc in lcarc:
                    proper_arc = tome.lcarcs[lcarc]
                    for title in tome.arcs[proper_arc]:
                        if title not in hits.keys():
                            hits[title] = list()
                        hits[title].append(proper_arc)

    if len(hits) > 0:
        for title in hits.keys():
            print("{} ({})".format(title, ', '.join(sorted(hits[title]))))


else:
    parser.print_help()
